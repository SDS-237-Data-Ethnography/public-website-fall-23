---
title: "Example Field Notes"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
library(lubridate)
```


## SDS 237 Spring '23: Casey MacGibbon

```{r metadata_1, echo=FALSE, results='asis'}
observer_1 <- "Casey MacGibbon"
date_observed_1 <- mdy("02/10/2023")
date_written_up_1 <- mdy("02/19/2023")
location_1 <- "The Human Performance Labratory, Scott Gym, Smith College"
cat(paste0("This entry documents a data environment ", observer_1, " observed on ", date_observed_1, " in ", location_1, ". The observations were written up on ", date_written_up_1, "."))
```

My stopwatch hits 20:00:00. 

"Alright, it’s been five minutes since I last asked, how rigorous do you feel your exercise is on a scale of 6-20?" I say, holding up a reference board for the participant. She points to a 12, which is labeled as "Somewhat hard." She is on minute twenty of her acute bout of exercise, where she is walking at a moderate pace on the treadmill, and we are monitoring her heart rate from an electronic wristband.

Recently, I have begun research work and analysis for the Witkowski Vascular Function Lab, and this was the first time I went in to observe a visit with a participant. I am new to the lab, and my perspective still feels a bit like an outsiders’. After the visit, I asked Dr. Witkowski explained that each number on the reference board corresponded to a heart rate by multiplying the number by 10, essentially acting as a participant’s heart rate experience. She explained to me how there are two different "data streams" throughout the lab, one being objective and the other subjective. 

The idea of objective/subjective data is an example of a binary opposition: a pair of terms with opposite meanings. I noticed how much more "objective" data collection was valued, while a lot of the data collected from the participant was thought of as "subjective," and thought of to be more subject to inaccuracy. Data is categorized as one or the other.
	
No data can be subjective, because the mere decision to begin collecting data means that there are expectations and biases put into the collection of data. Though the target heart rate is an "objective" part of the study because it is numerical, does not mean it is without bias. Heart rate calculations have historically ignored weight, height, average physical activity, and many other factors. This is just one example of how all of the data is biased, and cannot be placed into these categorizations.
Additionally, the "data streams" figure of speech is a part of popular data *discourse*, contributing to the idea that data is a natural resource waiting to be found, untainted and untouched by human interference.

Discourse is the way that people talk about and engage with a certain thing/person, and dominant discourse can often characterize how we think about this topic as a society. The imagery of a data stream indicates that data is natural and is something we can "drink" from at any time. In reality, all data is collected from humans, who are limited in their standpoints and views.

## SDS 237 Spring '23: Elm Markert

```{r metadata_3, echo=FALSE, results='asis'}
observer_3 <- "Elm Markert"
date_observed_3 <- mdy("03/24/2023")
date_written_up_3 <- mdy("03/29/2023")
location_3 <- "CMB and email inbox"
cat(paste0("This entry documents a data environment ", observer_3, " observed on ", date_observed_3, " in ", location_3, ". The observations were written up on ", date_written_up_3, "."))
```

> Please note that certain details in this entry were anonymized for the purposes of sharing. Names and titles have been changed. 

The Center [redacted] is on the first floor of [redacted] down a long hall of labs. I go there regularly for my research project and am always greeted with a friendly face – Morgan. They're the technical director of the Center and help students with research. This includes teaching students to use instruments that some senior researchers don’t even get their hands on. They're a patient teacher and helpful during experiments. They're also a core part of a lot of the data **labor** (work that goes into creating, supporting, processing, and analyzing information) that happens in my research field.

While Morgan is highly valued on a personal amongst colleagues, on an institutional level, they disappear a little bit. While most people outside the department recognize the research professors do, Morgan fades into the background a little more. They also don't get to do their own research, and the Center's budget is generally devoted to making sure professors get what they need for their research. As a result, despite the amount that they help with student research, Morgan rarely gets put on papers as an author. 

However, Morgan does love their job. They're excellent at training people on equipment and prefer being technical support to lecturing. They know the ins and outs of the instruments and do more hands-on work than most professors. Data produced in the Center is as accurate and uncontaminated as possible because of the care that they take when working. The data provides an excellent basis for publications. However, the labor that went into creating that data is hidden in the final publication. 

This obscuration of labor says a lot about what kind of labor academia values. Spoiler alert: it’s not "grunt" work. Instead, it values high level thinking. This ignores that the "grunt" work also requires expertise and is vital to the research that professors do. As an undergraduate researcher who gets to be first author but also is doing the "grunt" work, it is easy to see this discrepancy. I do actively benefit from this hierarchy in many ways because of my educational and career trajectory, but it appears that the more one benefits, the harder it is to notice. This is partially because the people who benefit most often don’t do much lab work. 

...I will add more as I get permission from former students.